---
layout: post
title:  "GPGPU: When CPU is not enough"
author:
    - paul.gelas@epitech.eu
categories: [ talk ]
image: assets/images/gpgpu/poster.png
published: true
comments: false
---

CPUs and GPUs play different roles in a micro-computer lifecycle. CPU -- Central Processing Unit -- is usually understood as the brain of the computer, responsible of carrying out all the tasks. GPU is a more specialized processing unit, designed for rapid mathematical calculations and traditionnally used for graphic and video rendering.

Thanks to the exponentially growing need of power for interactive video and graphic rendering in the computer science industry, GPU technology has expanded incredibily over the past years -- GPUs chip performances are growing very fast and developers are even able to use them way beyond graphics and video purposes.

This article is a technical presentation of a General-Purpose Graphics Processing Units (GPGPU) which is graphic processing unit (GPU) programmed for purposes beyond graphics processing, such as performing computation typically conducted by a Central Processing Unit (CPU). GPGPU computing refers to the increasingly commonplace, modern trend of using GPUs for non-specialized computation in addition to their traditional purpose of computation for computer graphics.

## What is GPGPU or General Purpose Graphics Processing Unit ?

There are two answers to this question :

Both are used to enhances CPU architecture by accelerating portions of an application while the rest continues to run on the CPU, ultimately creating an overall faster, high-performance application by combining CPU and GPU processing power. Although most program that uses GPGPU computing only uses GPU while waiting on idle on the CPU.

## Central Processing Unit

- A lot of space for Control Units that decodes instructions and coordinates how data moves around.
- Few Arithmetic Logic Unit that executes all calculations.
- High speed memory Unit (Cache).

![Figure01-InsideCPU]({{ site.baseurl }}/assets/images/gpgpu/figure01.png)

All these components work together to provide an environment where high-speed task parallelism can take place. As the CPU clock drives activities, the CPU cores switch rapidly between hundreds of different tasks per second. That is why your computer can run multiple programs, display something, connect to internet, and more all at the same time.

## Graphics Processing Unit (GPU)

What is inside a GPU:
- Lots of cores
- Lots of Arithmetic Logic Units per core
- High speed memory
  
The challenge in processing graphics is that graphics call on complex mathematics to render, and those complex mathematics must compute in parallel to work correctly.

For example, a graphically intense video game might contain hundreds or thousands of polygons on the screen at any given time, each with its individual movement, colour, lighting, and so on. CPUs are not made to handle that kind of workload. That is where graphical processing units (GPUs) come into play.

![Figure02-DRAM]({{ site.baseurl }}/assets/images/gpgpu/figure02.png)

### AMD GPU

Architecture of an AMD GPU

We have the GPU Compute Device that contains multiple Compute Unit (named SIMD engines) that contains multiple Stream Cores that contains multiple Processing Elements.

Here is an example with the AMD 5770 Card:
- 10 computes Units
- 16 cores by Units
- 5 Processing Elements per core

![Figure03-ArchitectureAMDGPU]({{ site.baseurl }}/assets/images/gpgpu/figure03.png)

We calculate the speed of a GPU with teraflop Saying something has "6 TFLOPS", for example, means that its processor setup can handle 6 trillion floating-point calculations every second, on average.
This card supports over 4 TFLOPS.

![Figure04-CardT4-FLOPS]({{ site.baseurl }}/assets/images/gpgpu/figure04.png)

And here is one SIMD Engine. All cores from the same Compute Unit run the same sequences of instructions.

![Figure05-OneSIMDEngine]({{ site.baseurl }}/assets/images/gpgpu/figure05.png)

### NVIDIA GPU

Architecture of an NVIDIA GPU
The compute device contains Streaming Multiprocessors (SM) which contains Cuda Cores.

![Figure06-Streaming-Multiprocessors-Cuda-Cores]({{ site.baseurl }}/assets/images/gpgpu/figure06.png)

On newer NVDIA GPU (Gen 3000, Ampere microarchitecture), there is 2 other types of cores:
- [Ray Tracing Cores][1], they are dedicated to performing ray-tracing operations and are not used for GPGPU computing
- [Tensor Cores][2] are specifically designed to perform matrix operation. The first generation was designed specifically for deep learning.

Matrixes computation takes the longest time in GPGPU computing, it is therefore now used for various purpose example: DLSS

![Figure07-RT-Core-Advanced]({{ site.baseurl }}/assets/images/gpgpu/figure07.png)

Each Cuda core contains an Arithmetic Logic Unit and a Floating Point Unit (ALUFPU).

![Figure08-ALUFPU]({{ site.baseurl }}/assets/images/gpgpu/figure08.png)

## Open Computing Language (OpenCL)

Created by Apple, OpenCL is a framework for writing programs that execute across heterogeneous platforms consisting of central processing unit (CPUs) and graphics processing units (GPUs). Both AMD and NVDIA devices uses the same protocol to communicate: Installable Client Driver ICD, which mean that in theory they can coexist. (There can be some exceptions) The app only must connect to the dynamic library.

![Figure09-GPUApp]({{ site.baseurl }}/assets/images/gpgpu/figure09.png)

If You want to introduce yourself to OpenCL programming, you can check this presentation from University of Laval (only in French) "4a-OpenCL".

## Cuda

An alternative is to use Cuda instead. It is only available	on NVIDIA GPU but it is a lot easier. Where you need more than 100 line to do simple actions with OpenCL, you only need 20 with Cuda. Changes are mostly that it does not need to check each GPU and verify if there is the library installed for them.

If you want to introduce yourself to Cuda I suggest you check this [post][3]

## Use-Cases

There are lots of applications for GPGPU computing but the most common ones are:
Video processing, Audio processing, Machine learning / Data mining, Bioinformatics, cryptography, crypto mining and many more. All these cases have lots of easy computation that can benefit from GPU architecture.

## My interest

I choose to study this subject to have a better understanding on how A GPU is used when doing neural network training. As said before, newer tensors cores on NVIDIA card were specifically designed for deep-learning and have greatly increased the speed of neural network training and made GPU training a mandatory part when doing machine learning.

[1]: (https://developer.nvidia.com/nvidia-ampere)
[2]: (https://www.nvidia.com/en-us/data-center/tensor-cores/)
[3]: (https://developer.nvidia.com/blog/even-easier-introduction-cuda/)